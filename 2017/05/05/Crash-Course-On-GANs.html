<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel="shortcut icon" type="image/x-icon" href="/devblog3/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Crash Course On GANs | Scott H. Hawley (alt. blog via fastpages)</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Crash Course On GANs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post is not necessarily a crash course on GANs. It is at least a record of me giving myself a crash course on GANs. Adding to this as I go." />
<meta property="og:description" content="This post is not necessarily a crash course on GANs. It is at least a record of me giving myself a crash course on GANs. Adding to this as I go." />
<link rel="canonical" href="https://drscotthawley.github.io/devblog3/2017/05/05/Crash-Course-On-GANs.html" />
<meta property="og:url" content="https://drscotthawley.github.io/devblog3/2017/05/05/Crash-Course-On-GANs.html" />
<meta property="og:site_name" content="Scott H. Hawley (alt. blog via fastpages)" />
<meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*-gFsbymY9oJUQJ-A3GTfeg.png?h" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-05-05T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://drscotthawley.github.io/devblog3/2017/05/05/Crash-Course-On-GANs.html"},"url":"https://drscotthawley.github.io/devblog3/2017/05/05/Crash-Course-On-GANs.html","@type":"BlogPosting","image":"https://cdn-images-1.medium.com/max/2000/1*-gFsbymY9oJUQJ-A3GTfeg.png?h","headline":"Crash Course On GANs","dateModified":"2017-05-05T00:00:00-05:00","datePublished":"2017-05-05T00:00:00-05:00","description":"This post is not necessarily a crash course on GANs. It is at least a record of me giving myself a crash course on GANs. Adding to this as I go.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
  <link rel="stylesheet" href="/devblog3/assets/main.css">
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://drscotthawley.github.io/devblog3/feed.xml" title="Scott H. Hawley (alt. blog via fastpages)" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
          ]}
        );
      });
    </script>
  

  <script>
  function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
  }
  window.onload = wrap_img;
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function(){
      // add link icon to anchor tags
      var elem = document.querySelectorAll(".anchor-link")
      elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
      // remove paragraph tags in rendered toc (happens from notebooks)
      var toctags = document.querySelectorAll(".toc-entry")
      toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
  </script>
</head><body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/devblog3/">Scott H. Hawley (alt. blog via fastpages)</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/devblog3/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Crash Course On GANs</h1>
    <p class="post-meta"><time class="dt-published" datetime="2017-05-05T00:00:00-05:00" itemprop="datePublished">
        May 5, 2017
      </time>•<span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>
    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*-gFsbymY9oJUQJ-A3GTfeg.png?h" alt="header-img" /></p>
<p style="text-align: right"><i>Image credit: <a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f">Dev Nag</a></i></p>

<p><em>This post is not necessarily a crash course on GANs. It is at least a record of me giving myself a crash course on GANs.  Adding to this as I go.</em></p>

<h2 id="intromotivation">Intro/Motivation</h2>
<p>I’ve been wanting to grasp the seeming-magic of Generative Adversarial Networks (GANs) since I started seeing <a href="https://github.com/SKTBrain/DiscoGAN">handbags turned into shoes and brunettes turned to blondes</a>… 
<img src="https://raw.githubusercontent.com/SKTBrain/DiscoGAN/master/assets/discogan.png" alt="hbg-shoe" />
…and seeing <a href="https://techcrunch.com/2016/04/14/magic-ponys-neural-network-dreams-up-new-imagery-to-expand-an-existing-picture/">Magic Pony’s image super-resolution results</a> and hearing that <a href="https://twitter.com/ylecun">Yann Lecun</a> had called GANs <a href="https://www.quora.com/session/Yann-LeCun/1">the most important innovation in machine learning in recent years</a>.</p>

<p>Finally, seeing Google’s <a href="https://research.googleblog.com/2017/04/teaching-machines-to-draw.html">Cat-Pig Sketch-Drawing Math</a>…
<img src="https://4.bp.blogspot.com/-yK7t-68XTzA/WO6XNTIb66I/AAAAAAAABuM/PqB64rz_YgMYM3EkP2BEJojnCLHsAMXqgCLcB/s640/image05.png" alt="catpig" /></p>

<p>…broke me, and so…I need to ‘get’ this.</p>

<p>I’ve noticed that, although people use GANs with great success for images, not many have tried using them for audio yet (<strong>Note:</strong> see SEGAN paper, below).  Maybe with already-successful generative audio systems like <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet</a>, <a href="https://github.com/soroushmehr/sampleRNN_ICLR2017">SampleRNN</a> (listen to those piano sounds!!) and <a href="https://google.github.io/tacotron/">TacoTron</a> there’s less of a push for trying GANs.  Or maybe GANs just suck for audio.  Guess I’ll find out…</p>

<h2 id="steps-i-took">Steps I Took</h2>
<h3 id="day-1">Day 1:</h3>
<ol>
  <li>Gathered list of some prominent papers (below).</li>
  <li>Watched video of <a href="https://www.youtube.com/watch?v=JRKl9QPiRok">Ian Goodfellow’s Berkeley lecture</a> (notes below).</li>
  <li>Started reading the <a href="https://arxiv.org/abs/1609.03126">EBGAN paper</a> (notes below)…</li>
  <li>…but soon switched to <a href="https://arxiv.org/abs/1703.10717">BEGAN paper</a> – because wow! Look at these generated images: <img src="https://heuritech.files.wordpress.com/2017/04/1_face_teaser.png?w=1595&amp;h=955" alt="Sample Images" /></li>
  <li>Googled for Keras-based BEGAN implementations and other code repositories (below)…Noticed <a href="https://arxiv.org/abs/1703.09452">SEGAN</a>…</li>
  <li>…Kept reading BEGAN, making notes as I went (below).</li>
  <li>
    <p>Finished paper, started looking through BEGAN codes from GitHub (below) &amp; began trying them out…<br />
 a. Cloned <a href="https://github.com/mokemokechicken/keras_BEGAN">@mokemokechicken’s Keras repo</a>, grabbed suggested LFW database, converted images via script, ran training… Takes 140 seconds per epoch on Titan X Pascal.</p>

    <ul>
      <li>Main part of code is in <a href="https://github.com/mokemokechicken/keras_BEGAN/blob/master/src/began/models.py">models.py</a></li>
    </ul>

    <p>b. Cloned <a href="https://github.com/carpedm20/BEGAN-tensorflow">@carpedm’s Tensorflow repo</a>, looked through it, got CelebA dataset, started running code.</p>
  </li>
  <li>Leaving codes to train overnight. Next time, I’d like to try to better understand the use of an autoencoder as the discriminator.</li>
</ol>

<h3 id="day-2">Day 2:</h3>
<ol>
  <li>My office is <span style="color:red">hot</span>.  Two Titan X GPUs pulling ~230W for 10 hours straight has put the cards up towards annoyingly high temperatures, as in ~ 85 Celsius!  My previous nightly runs wouldn’t even go above 60 C.   But the results – espically from the straight-Tensorflow code trained on the CelebA dataset – are as incredible as advertised!  (Not that I understand them yet. LOL.)  The Keras version, despite claiming to be a BEGAN implementation, seems to suffer from “mode collapse,” i.e. that too many very similar images get generated.</li>
  <li>Fished around a little more on the web for audio GAN applications.  Found an <a href="https://arxiv.org/abs/1611.09904">RNN-GAN application to MIDI</a>, and found actual audio examples of <a href="http://deepsound.io/dcgan_spectrograms.html">what not to do: don’t try to just produce spectrograms with DCGAN and convert them to audio</a>.  The latter authors seem to have decided to switch to a SampleRNN approach.  Perhaps it would be wise to heed their example? ;-)</li>
  <li>Since EBGAN implemented autoencoders as discriminators before BEGAN did, I went back to read that part of the EBGAN paper. Indeed, section “2.3 - Using AutoEncoders” (page 4). (see notes below)</li>
  <li>Ok, I basically get the autoencoder-discriminator thing now. :-)</li>
</ol>

<h3 id="day-3">Day 3:</h3>
<p>“Life” intervened. :-/  Hope to pick this up later.</p>

<h2 id="papers">Papers</h2>
<p>Haven’t read hardly any of these yet, just gathering them here for reference:</p>

<ul>
  <li>Original GAN Paper: <a href="https://arxiv.org/abs/1406.2661">” Generative Adversarial Networks”</a> by GoodFellow (2014)</li>
  <li>DCGAN: <a href="https://arxiv.org/abs/1511.06434">“Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks”</a> by Radford, Metz \&amp; Chintala (2015)</li>
  <li><a href="https://arxiv.org/abs/1611.07004">“Image-to-Image Translation with Conditional Adversarial Networks”</a> by Isola et al (2016)</li>
  <li><a href="https://arxiv.org/abs/1606.03498">“Improved Techniques for Training GANs”</a> by Salimans et al (2016).</li>
  <li>DiscoGAN: <a href="https://arxiv.org/pdf/1703.05192.pdf">“Learning to Discover Cross-Domain Relations
with Generative Adversarial Networks”</a> by Kim et al. (2017)</li>
  <li>EBGAN: <a href="https://arxiv.org/abs/1609.03126">“Energy-based Generative Adversarial Network</a> by Zhao, Matheiu \&amp; Lecun (2016/2017).
    <ul>
      <li><strong>Remarks/Notes:</strong></li>
      <li>“This variant [EBGAN] converges more stably [than previous GANs] and is both easy to train and robust to hyper-parameter variations” (quoting from BEGAN paper, below).</li>
      <li>If it’s energy-based, does that mean we get a Lagrangian, and Euler-Lagrange Equations, and Lagrange Multipliers?  And thus can physics students (&amp; professors!) grasp these networks in a straightforward way?  Should perhaps take a look at Lecun’s <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf">Tutorial on Energy-Based Learning</a>.</li>
      <li>“The energy is the resconstruction error [of the autoencoder]” (Section 1.3, bullet points)</li>
      <li><img src="http://kordinglab.com/lab_teaching_2016/session_4/images/ebgan.jpg" alt="ebgan-pic" /></li>
    </ul>
    <p style="text-align: right"><i>Image credit: <a href="http://kordinglab.com/lab_teaching_2016/session_4/">Roozbeh Farhoodi</a> + EBGAN authors</i></p>
    <ul>
      <li>“…256×256 pixel resolution, without a multi-scale approach.” (ibid)</li>
      <li>Section 2.3 covers on the use of the autoencoder as a discriminator.  Wow, truly, the discriminator’s “energy”/ “loss” criterion is literally just the reconstruction error of the autoencoder. How does that get you a discriminator??</li>
      <li>It gets you a discriminator because the outputs of the generator are likely to have high energies whereas the real data (supposedly) will produce low energies: “We argue that the energy function (the discriminator) in the EBGAN framework is also seen as
being regularized by having a generator producing the contrastive samples, to which the discrim-
inator ought to give high reconstruction energies” (bottom of page 4).</li>
    </ul>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1701.07875.pdf">“Wasserstein GAN (WGAN)</a> by Arjovsky, Chintala, \&amp; Bottou (2017)</p>
  </li>
  <li>
    <h3 id="began-boundary-equilibrium-generative-adversarial-networks-by-berthelot-schumm--metz-april-2017"><a href="https://arxiv.org/abs/1703.10717">“BEGAN: Boundary Equilibrium Generative Adversarial Networks”</a> by Berthelot, Schumm &amp; Metz (April 2017).</h3>
    <ul>
      <li><strong>Remarks/Notes:</strong></li>
      <li><em>“Our model is easier to train and simpler than other GANs architectures: no batch normalization, no dropout, no transpose convolutions and no exponential growth for convolution filters.”</em> (end of section 3.5, page 5)</li>
      <li>This is probably not the kind of paper that anyone off the street can just pick up \&amp; read.  <em>There will be math.</em></li>
      <li>Uses an autoencoder for the discriminator.</li>
      <li>I notice that Table 1, page 8 shows “DFM” (from <a href="https://openreview.net/pdf?id=S1X7nhsxl">“Improving Generative Adversarial Networks
with Denoising Feature Matching”</a> by Warde-Farley &amp; Bengio, 2017) as scoring higher than BEGAN.</li>
      <li>page 2: “Given two normal distributions…with covariances <script type="math/tex">C_1, C_2</script>,…”: see <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">“Multivariate Normal Distribution”</a>.</li>
      <li>Section 3.3, Equilibrium: The “<script type="math/tex">\mathbb{E}[\  ]</script>” notation – as in <script type="math/tex">\mathbb{E}\left[\mathcal{L}(x)\right]</script> – means “expected value.”  See <a href="https://en.wikipedia.org/wiki/Expected_value">https://en.wikipedia.org/wiki/Expected_value</a></li>
      <li>Introduces the <em>diversity ratio</em>: <script type="math/tex">\gamma=\frac{\mathbb{E}\left[\mathcal{L}(G(z))\right]}{\mathbb{E}\left[\mathcal{L}(x)\right]}</script>.  “Lower values of <script type="math/tex">\gamma</script> lead to lower image diversity because the discriminator focuses more heavily on auto-encoding real images.”</li>
      <li>“3.5 Model architecture”: Did not actually get the bit about the autoencoder as the discriminator: “How does an autoencoder output a 1 or a zero?”</li>
      <li>Ok, done. Will come back later if needed; maybe looking at code will make things clearer…</li>
    </ul>
  </li>
  <li><a href="https://arxiv.org/pdf/1703.09452.pdf">“SEGAN: Speech Enhancement Generative Adversarial Network”</a> by Pascual, Bonafonte \&amp; Serra (April 2017). <strong>Actual audio GAN!</strong> They only used it to remove noise.</li>
</ul>

<h2 id="videos">Videos</h2>

<ul>
  <li><a href="https://www.youtube.com/watch?v=JRKl9QPiRok">Ian Goodfellow (original GAN author), Guest lecture on GANs for UC Berkeley CS295</a> (Oct 2016). 1 hour 27 minutes. <em>NOTE: actually starts at 4:33.</em> Watch at 1.25 speed.
    <ul>
      <li><strong>Remarks/Notes:</strong></li>
      <li><em>This is on a fairly “high” level</em>, which may be too much for some viewers; if hearing the words “probability distribution” over &amp; over again makes you tune out, and e.g. if you don’t know what a Jacobian is, then you may not want to watch this.</li>
      <li>His “Taxonomy of Generative Models” is <strong>GREAT!</strong></li>
      <li>The discriminator is just an ordinary classifier.</li>
      <li>So, the generator’s cost function can be just the negative of the discriminator’s cost function, (i.e. it tries to “mess up” the discriminator), however that can saturate (i.e. produce small gradients) so instead they try to “maximize the probability that the discriminator will make a mistake” (44:12).</li>
      <li><a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">“KL divergence”</a> is a measure of the ‘difference’ between two PD’s.</li>
      <li><a href="https://en.wikipedia.org/wiki/Logit">“Logit”</a> is the inverse of the sigmoid/logistical function. (logit&lt;–&gt;sigmoid :: tan&lt;–&gt;arctan)</li>
      <li><a href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen-Shannon divergence</a> is a measure of the ‘similarity’ between two PD’s.  Jensen-Shannon produces better results for GANs than KL/maximum likelihood.</li>
    </ul>
  </li>
</ul>

<h2 id="web-poststutorials">Web Posts/Tutorials</h2>
<ul>
  <li><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7">“Machine Learning is Fun Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art”</a> by Adam Geitgey, <em>skip down to “How DCGANs Work”</em> (2017)</li>
  <li>Post on BEGAN: <a href="https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/">https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/</a></li>
  <li><a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow">An introduction to Generative Adversarial Networks (with code in TensorFlow)</a></li>
  <li><a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f">“Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)”</a> by Dev Nag (2017)</li>
  <li><a href="http://www.araya.org/archives/1183">“Stability of Generative Adversarial Networks”</a> by Nicholas Guttenberg (2016)</li>
  <li>
    <p><a href="http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html">“End to End Neural Art with Generative Models”</a> by Bing Xu (2016)</p>
  </li>
  <li>
    <h3 id="kording-lab-gan-tutorial-by-roozbeh-farhoodi----nicely-done-has-code-too"><a href="http://kordinglab.com/lab_teaching_2016/session_4/#1">Kording Lab GAN Tutorial</a> by Roozbeh Farhoodi :-).  Nicely done, <a href="https://github.com/KordingLab/lab_teaching_2016">has code too</a>.</h3>
  </li>
</ul>

<h2 id="code">Code</h2>
<h3 id="keras">Keras:</h3>
<ul>
  <li>‘Basic’ GAN with MNIST example: <a href="http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html">http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html</a></li>
  <li>GAN, BiGAN \&amp; Adversarial AutoEncoder: <a href="https://github.com/bstriner/keras-adversarial">https://github.com/bstriner/keras-adversarial</a></li>
  <li><strong>Kording Lab’s GAN tutorial, Jupyter Notebook <a href="https://github.com/KordingLab/lab_teaching_2016/blob/master/session_4/Generative%20Adversarial%20Networks.ipynb">https://github.com/KordingLab/lab_teaching_2016/blob/master/session_4/Generative%20Adversarial%20Networks.ipynb</a>.  (Code is short and understandable.)</strong></li>
  <li>Keras BEGAN:
    <ul>
      <li><a href="https://github.com/mokemokechicken/keras_BEGAN">https://github.com/mokemokechicken/keras_BEGAN</a>: Only works on 64x64 images; BEGAN paper shows some 128x128</li>
      <li><a href="https://github.com/pbontrager/BEGAN-keras">https://github.com/pbontrager/BEGAN-keras</a>: No documentation, and I don’t see how it could run.  I notice local variables being referenced in <a href="https://github.com/pbontrager/BEGAN-keras/blob/master/models.py">models.py</a> as if they’re global.</li>
    </ul>
  </li>
  <li>Keras DCGAN (MNIST): <a href="https://github.com/jacobgil/keras-dcgan">https://github.com/jacobgil/keras-dcgan</a></li>
  <li>Auxiliary Classifier GAN: <a href="https://github.com/lukedeo/keras-acgan">https://github.com/lukedeo/keras-acgan</a></li>
</ul>

<h3 id="tensorflow">Tensorflow:</h3>
<ul>
  <li>BEGAN-Tensorflow: <a href="https://github.com/carpedm20/BEGAN-tensorflow">https://github.com/carpedm20/BEGAN-tensorflow</a></li>
  <li>EBGAN.Tensorflow: <a href="https://github.com/shekkizh/EBGAN.tensorflow">https://github.com/shekkizh/EBGAN.tensorflow</a></li>
  <li>SEGAN: <a href="https://github.com/santi-pdp/segan">https://github.com/santi-pdp/segan</a></li>
  <li>DCGAN-Tensorflow: <a href="https://github.com/carpedm20/DCGAN-tensorflow">https://github.com/carpedm20/DCGAN-tensorflow</a></li>
</ul>

<h3 id="pytorch">PyTorch:</h3>
<ul>
  <li>Tutorial &amp; simple implementation: <a href="https://github.com/devnag/pytorch-generative-adversarial-networks">https://github.com/devnag/pytorch-generative-adversarial-networks</a></li>
</ul>

<h2 id="datasets">Datasets</h2>
<ul>
  <li>CelebA: <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a></li>
  <li>MNIST: <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></li>
  <li>Speech enhancement: <a href="http://datashare.is.ed.ac.uk/handle/10283/1942">http://datashare.is.ed.ac.uk/handle/10283/1942</a></li>
  <li>“Labelled Faces in the Wild” <a href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></li>
</ul>

<h2 id="more-references-lists">More References (Lists)</h2>
<ul>
  <li><a href="https://github.com/GKalliatakis/Delving-deep-into-GANs">“Delving deep into Generative Adversarial Networks (GANs): A curated list of state-of-the-art publications and resources about Generative Adversarial Networks (GANs) and their applications.”</a></li>
</ul>

  </div>
  

<style>
#share-buttons {display: inline-block; vertical-align: middle; }
#share-buttons:after {content: ""; display: block; clear: both;}
#share-buttons > div {
    position: relative;
    text-align: left; 
    height: 36px; 
    width: 32px; 
    float: left; 
    text-align: center;
}
#share-buttons > div > svg {height: 16px; fill: #d5d5d5; margin-top: 10px;}
#share-buttons > div:hover {cursor: pointer;}
#share-buttons > div.facebook:hover > svg {fill: #3B5998;}
#share-buttons > div.twitter:hover > svg {fill: #55ACEE;}
#share-buttons > div.linkedin:hover > svg {fill: #0077b5;}
#share-buttons > div.pinterest:hover > svg {fill: #CB2027;}
#share-buttons > div.gplus:hover > svg {fill: #dd4b39;}
#share-buttons > div.mail:hover > svg {fill: #7D7D7D;}
#share-buttons > div.instagram:hover > svg {fill: #C73B92;}
#share-buttons > div.facebook > svg {height: 18px; margin-top: 9px;}
#share-buttons > div.twitter > svg {height: 20px; margin-top: 8px;}
#share-buttons > div.linkedin > svg {height: 19px; margin-top: 7px;}
#share-buttons > div.pinterest > svg {height: 20px; margin-top: 9px;}
#share-buttons > div.gplus > svg {height: 17px; margin-top: 9px; position: relative; left: 1px;}
#share-buttons > div.mail > svg {height: 14px; margin-top: 11px;}
</style>

<span style="color: silver;">Share on: </span><div id="share-buttons">
    <div class="facebook" title="Share this on Facebook" onclick="window.open('http://www.facebook.com/share.php?u=https://drscotthawley.github.io/2017/05/05/Crash-Course-On-GANs.html');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1343 12v264h-157q-86 0-116 36t-30 108v189h293l-39 296h-254v759h-306v-759h-255v-296h255v-218q0-186 104-288.5t277-102.5q147 0 228 12z"/></svg></div>
    <div class="twitter" title="Share this on Twitter" onclick="window.open('http://twitter.com/home?status=https://drscotthawley.github.io/2017/05/05/Crash-Course-On-GANs.html');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1684 408q-67 98-162 167 1 14 1 42 0 130-38 259.5t-115.5 248.5-184.5 210.5-258 146-323 54.5q-271 0-496-145 35 4 78 4 225 0 401-138-105-2-188-64.5t-114-159.5q33 5 61 5 43 0 85-11-112-23-185.5-111.5t-73.5-205.5v-4q68 38 146 41-66-44-105-115t-39-154q0-88 44-163 121 149 294.5 238.5t371.5 99.5q-8-38-8-74 0-134 94.5-228.5t228.5-94.5q140 0 236 102 109-21 205-78-37 115-142 178 93-10 186-50z"/></svg></div>
    <div class="linkedin" title="Share this on Linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?mini=true&url=https://drscotthawley.github.io/2017/05/05/Crash-Course-On-GANs.html&title=&summary=&source=');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M477 625v991h-330v-991h330zm21-306q1 73-50.5 122t-135.5 49h-2q-82 0-132-49t-50-122q0-74 51.5-122.5t134.5-48.5 133 48.5 51 122.5zm1166 729v568h-329v-530q0-105-40.5-164.5t-126.5-59.5q-63 0-105.5 34.5t-63.5 85.5q-11 30-11 81v553h-329q2-399 2-647t-1-296l-1-48h329v144h-2q20-32 41-56t56.5-52 87-43.5 114.5-15.5q171 0 275 113.5t104 332.5z"/></svg></div>
    <div class="pinterest" title="Share this on Pinterest" onclick="window.open('https://pinterest.com/pin/create/button/?url=&media=https://drscotthawley.github.iohttps://cdn-images-1.medium.com/max/2000/1*-gFsbymY9oJUQJ-A3GTfeg.png?h&description=');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M256 597q0-108 37.5-203.5t103.5-166.5 152-123 185-78 202-26q158 0 294 66.5t221 193.5 85 287q0 96-19 188t-60 177-100 149.5-145 103-189 38.5q-68 0-135-32t-96-88q-10 39-28 112.5t-23.5 95-20.5 71-26 71-32 62.5-46 77.5-62 86.5l-14 5-9-10q-15-157-15-188 0-92 21.5-206.5t66.5-287.5 52-203q-32-65-32-169 0-83 52-156t132-73q61 0 95 40.5t34 102.5q0 66-44 191t-44 187q0 63 45 104.5t109 41.5q55 0 102-25t78.5-68 56-95 38-110.5 20-111 6.5-99.5q0-173-109.5-269.5t-285.5-96.5q-200 0-334 129.5t-134 328.5q0 44 12.5 85t27 65 27 45.5 12.5 30.5q0 28-15 73t-37 45q-2 0-17-3-51-15-90.5-56t-61-94.5-32.5-108-11-106.5z"/></svg></div>
    <div class="gplus" title="Share this on Google Plus" onclick="window.open('https://plus.google.com/share?url=https://drscotthawley.github.io/2017/05/05/Crash-Course-On-GANs.html');"><svg viewBox="0 0 2304 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1437 913q0 208-87 370.5t-248 254-369 91.5q-149 0-285-58t-234-156-156-234-58-285 58-285 156-234 234-156 285-58q286 0 491 192l-199 191q-117-113-292-113-123 0-227.5 62t-165.5 168.5-61 232.5 61 232.5 165.5 168.5 227.5 62q83 0 152.5-23t114.5-57.5 78.5-78.5 49-83 21.5-74h-416v-252h692q12 63 12 122zm867-122v210h-209v209h-210v-209h-209v-210h209v-209h210v209h209z"/></svg></div>
    <div class="mail" title="Share this through Email" onclick="window.open('mailto:?&body=https://drscotthawley.github.io/2017/05/05/Crash-Course-On-GANs.html');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1792 710v794q0 66-47 113t-113 47h-1472q-66 0-113-47t-47-113v-794q44 49 101 87 362 246 497 345 57 42 92.5 65.5t94.5 48 110 24.5h2q51 0 110-24.5t94.5-48 92.5-65.5q170-123 498-345 57-39 100-87zm0-294q0 79-49 151t-122 123q-376 261-468 325-10 7-42.5 30.5t-54 38-52 32.5-57.5 27-50 9h-2q-23 0-50-9t-57.5-27-52-32.5-54-38-42.5-30.5q-91-64-262-182.5t-205-142.5q-62-42-117-115.5t-55-136.5q0-78 41.5-130t118.5-52h1472q65 0 112.5 47t47.5 113z"/></svg></div>
</div><a class="u-url" href="/devblog3/2017/05/05/Crash-Course-On-GANs.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/devblog3/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Scott H. Hawley (alt. blog via fastpages)</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Scott H. Hawley (alt. blog via fastpages)</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/drscotthawley"><svg class="social svg-icon"><use xlink:href="/devblog3/assets/minima-social-icons.svg#github"></use></svg> <span class="username">drscotthawley</span></a></li><li><a href="https://www.twitter.com/%40drscotthawley"><svg class="social svg-icon"><use xlink:href="/devblog3/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">@drscotthawley</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>An alternate copy of my development blog, using fastpages. If successful I will replace the main blog with this</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
